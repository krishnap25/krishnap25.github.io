---
title: "Publications/Manuscripts"
author_profile: true
redirect_from: 
  - /publications.html
---

{% include base_path %}



<!-- Leave two spaces at the end -->

**Federated Learning with Superquantile Aggregation for Heterogeneous Data.**  
Krishna Pillutla\*, Yassine Laguel\*, Jérôme Malick, Zaid Harchaoui.  
*Machine Learning (To Appear, 2022).*  
Short version: *[FL-NeurIPS '22](https://federated-learning.org/fl-neurips-2022/), [DistShift-NeurIPS '22](https://sites.google.com/view/distshift2022) **Spotlight**.*  
[PDF](https://arxiv.org/pdf/2112.09429.pdf) &nbsp;
[Code](https://github.com/krishnap25/simplicial-fl) &nbsp;
[Slides](/slides/simplicial-fl-informs.pdf)  &nbsp;
[Poster](/papers/2022_sfl-distshift-poster.pdf) &nbsp;


**From Enormous Structured Models to On-device Federated Learning: Robustness, Heterogeneity and Optimization.**  
Krishna Pillutla  
*PhD Dissertation (2022)*.  
[PDF](/papers/phd_dissertation_kpillutla.pdf) &nbsp;
[Slides](/slides/defense.pdf)


**Federated Learning with Partial Model Personalization.**  
Krishna Pillutla, Kshitiz Malik, Abdelrahman Mohamed, Michael Rabbat, Maziar Sanjabi, Lin Xiao.  
*ICML 2022*.  
[PDF](https://arxiv.org/pdf/2204.03809.pdf) &nbsp;
[Code](https://github.com/facebookresearch/FL_partial_personalization) &nbsp;
[Slides (ICML Spotlight)](/slides/pfl_icml.pdf)  &nbsp;
[Poster](/papers/2022_pfl_poster.pdf) &nbsp;


**Robust Aggregation for Federated Learning.**  
Krishna Pillutla, Sham Kakade, Zaid Harchaoui.  
*IEEE Transactions on Signal Processing (2022)*.  
[PDF](https://arxiv.org/pdf/1912.13445.pdf) &nbsp;
[Code (TensorFlow)](https://github.com/krishnap25/RFA) &nbsp;
[Code (PyTorch)](https://github.com/krishnap25/tRFA) &nbsp; 
[Talk video](https://www.youtube.com/watch?v=-wNV8pbMNQk)


**MAUVE: Measuring the Gap Between Neural Text and Human Text using Divergence Frontiers.**  
Krishna Pillutla, Swabha Swayamdipta, Rowan Zellers, John Thickstun, Sean Welleck, Yejin Choi, Zaid Harchaoui.  
*NeurIPS 2021. **Outstanding Paper Award** (Top 6 out of 9000 submissions)*.  
<!-- Previously titled: MAUVE: Human-Machine Divergence Curves for Evaluating Open-Ended Text Generation.   -->
[PDF](https://arxiv.org/pdf/2102.01454.pdf) &nbsp;
[Pip-package](https://github.com/krishnap25/mauve) &nbsp;
[Code](https://github.com/krishnap25/mauve-experiments) &nbsp;
[Poster](/papers/2021-mauve-poster.pdf) &nbsp; 
[Press](https://blog.neurips.cc/2021/11/30/announcing-the-neurips-2021-award-recipients/)  

**Divergence Frontiers for Generative Models: Sample Complexity, Quantization Level, and Frontier Integral.**  
Lang Liu, Krishna Pillutla, Sean Welleck, Sewoong Oh, Yejin Choi, Zaid Harchaoui.  
*NeurIPS 2021*.  
[PDF](https://arxiv.org/pdf/2106.07898.pdf) &nbsp; 
[Code](https://github.com/langliu95/divergence-frontier-bounds) 

**LLC: Accurate, Multi-purpose Learnt Low-dimensional Binary Codes.**  
Aditya Kusupati, Matthew Wallingford, Vivek Ramanujan, Raghav Somani, Jae Sung Park, Krishna Pillutla, Prateek Jain, Sham Kakade, Ali Farhadi.  
*NeurIPS 2021*.  
[PDF](https://arxiv.org/pdf/2106.01487.pdf)


**Superquantiles at Work : Machine Learning Applications and Efficient (Sub)gradient Computation.**  
Yassine Laguel, Krishna Pillutla, Jérôme Malick, Zaid Harchaoui.  
*Set-Valued and Variational Analysis (2021)*.  
[PDF](https://arxiv.org/pdf/2201.00508.pdf) &nbsp; &nbsp; 
[Publisher's Page](https://link.springer.com/article/10.1007/s11228-021-00609-w)

**A Superquantile Approach to Federated Learning with Heterogeneous Devices.**  
Yassine Laguel\*, Krishna Pillutla\*, Jérôme Malick, Zaid Harchaoui.  
*CISS 2021*.  
<!-- Previously titled: Device Heterogeneity in Federated Learning: A Superquantile Approach.   -->
[PDF](/papers/2021_Simplicial_FL_CISS.pdf)
[PDF-arXiv(old)](https://arxiv.org/pdf/2002.11223.pdf) 
&nbsp;
[Code](https://github.com/krishnap25/simplicial-fl)


**A Smoother Way to Train Structured Prediction Models.**  
Krishna Pillutla, Vincent Roulet, Sham Kakade, Zaid Harchaoui.  
*NeurIPS 2018*.  
[PDF-long](https://arxiv.org/pdf/1902.03228.pdf) &nbsp;
[PDF-short](/papers/2018_neurips_smoother.pdf) &nbsp;
[Code](https://github.com/krishnap25/casimir) &nbsp;
[Documentation](https://homes.cs.washington.edu/~pillutla/documentation/casimir/)  
[Poster](/papers/2018_neurips_smoother_poster.pdf) &nbsp;
[Blog post](http://ads-institute.uw.edu//blog/2018/12/17/deep-struct-pred/) &nbsp;
[Video summary](https://youtu.be/DkmroHdthvk)

**A Markov Chain Theory Approach to Characterizing the Minimax Optimality of Stochastic Gradient Descent (for Least Squares).**  
Prateek Jain, Sham M. Kakade, Rahul Kidambi, Praneeth Netrapalli, Venkata Krishna Pillutla, Aaron Sidford.  
*FSTTCS 2017*.  
[PDF](https://arxiv.org/pdf/1710.09430.pdf)

**Data Driven Resource Allocation for Distributed Learning.**  
Travis Dick, Mu Li, Venkata Krishna Pillutla, Colin White, Maria-Florina Balcan, Alex Smola.  
*AISTATS 2017*.  
[PDF-long](http://arxiv.org/abs/1512.04848) &nbsp;
[PDF-short](http://proceedings.mlr.press/v54/dick17a/dick17a.pdf) &nbsp;  

**On Skewed Multi-dimensional Distributions: the FusionRP Model, Algorithms, and Discoveries.**  
Venkata Krishna Pillutla*, Zhanpeng Fang*, Christos Faloutsos, Danai Koutra, Jie Tang.  
*SDM 2016*.


**Master's Thesis: Data Driven Resource Allocation For Distributed Machine Learning.**                 
Thesis Committee: Nina Balcan, Alex Smola, Christos Faloutsos  
     [PDF](/papers/mthesis.pdf) [Slides](/papers/mthesis_presentation.pdf)


<!-- The [DBLP](http://dblp.uni-trier.de/pers/hd/p/Pillutla:Venkata_Krishna) listing provides a comprehensive list of my publications. -->
